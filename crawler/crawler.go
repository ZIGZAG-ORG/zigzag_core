package crawler

import (
	"context"
	"fmt"
	"log"
	"strings"
	"time"

	"github.com/chromedp/chromedp"
)

func GoogleCrawler() {
	// Chrome ì‹¤í–‰ ì˜µì…˜ ì¶”ê°€
	opts := append(chromedp.DefaultExecAllocatorOptions[:],
		chromedp.ExecPath("/usr/bin/google-chrome"), // Chrome ì‹¤í–‰ ê²½ë¡œ ì„¤ì •
		chromedp.NoFirstRun,
		chromedp.NoDefaultBrowserCheck,
		chromedp.DisableGPU,
		chromedp.Headless, // í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í™œì„±í™”
		chromedp.Flag("disable-software-rasterizer", true),
		chromedp.Flag("enable-automation", false),
		chromedp.Flag("disable-dev-shm-usage", true), // Docker í™˜ê²½ì—ì„œ ë©”ëª¨ë¦¬ ë¬¸ì œ ë°©ì§€
	)

	// Chrome ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
	ctx, cancel := chromedp.NewExecAllocator(context.Background(), opts...)
	defer cancel()

	ctx, cancel = chromedp.NewContext(ctx)
	defer cancel()

	// ë‰´ìŠ¤ ì œëª©ê³¼ URLì„ ì €ì¥í•  ë³€ìˆ˜
	var titles, urls []string

	// í¬ë¡¤ë§ ì‹¤í–‰
	err := chromedp.Run(ctx,
		chromedp.Navigate(`https://www.google.com/search?lr=lang_en&cr=countryUS&sca_esv=4a0a8c718760d881&tbs=qdr:d,lr:lang_1en,ctr:countryUS&sxsrf=AHTn8zpR9dSRYHtsevgbXPR9jYxQ5SwT8g:1741345786008&q=tesla&tbm=nws&source=lnms`),
		chromedp.Sleep(2*time.Second), // í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

		// ë‰´ìŠ¤ ì œëª© ê°€ì ¸ì˜¤ê¸° (CSS ì„ íƒì ì‚¬ìš©)
		chromedp.Evaluate(`Array.from(document.querySelectorAll(".n0jPhd.ynAwRc.MBeuO.nDgy9d")).map(e => e.innerText)`, &titles),

		// ë‰´ìŠ¤ URL ê°€ì ¸ì˜¤ê¸° (a íƒœê·¸ì˜ href ì†ì„± í¬ë¡¤ë§)
		chromedp.Evaluate(`Array.from(document.querySelectorAll("a.WlydOe")).map(e => e.href)`, &urls),
	)

	if err != nil {
		log.Fatal(err)
	}

	// ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª© ë° URL ì¶œë ¥
	fmt.Println("ğŸ”— í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ê¸°ì‚¬ ëª©ë¡:")
	for i := range titles {
		// ìœ íš¨í•œ ë§í¬ë§Œ ì¶œë ¥
		if i < len(urls) && strings.HasPrefix(urls[i], "http") {
			fmt.Printf("ğŸ“Œ %s\nğŸ”— %s\n\n", titles[i], urls[i])
		}
	}
}
